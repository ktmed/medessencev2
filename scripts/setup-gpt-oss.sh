#!/bin/bash

# GPT-OSS-20B Setup Script for RadExtract Medical AI
# Downloads and configures GPT-OSS-20B for offline medical report processing

set -e

echo "ðŸ§  GPT-OSS-20B Setup for RadExtract Medical AI"
echo "=============================================="
echo ""

# Configuration
GPT_OSS_VERSION="gpt-oss-20b-q4_k_m.gguf"
MODELS_DIR="./gpt-oss-models"
DOWNLOAD_URL="https://huggingface.co/lmstudio-community/gpt-oss-20b-GGUF/resolve/main/$GPT_OSS_VERSION"

# Check system requirements
echo "ðŸ” Checking system requirements..."

# Check available RAM
if [[ "$OSTYPE" == "darwin"* ]]; then
    # macOS
    TOTAL_RAM_MB=$(sysctl -n hw.memsize | awk '{print int($1/1024/1024)}')
else
    # Linux
    TOTAL_RAM_KB=$(grep MemTotal /proc/meminfo 2>/dev/null | awk '{print $2}' || echo "0")
    TOTAL_RAM_MB=$((TOTAL_RAM_KB / 1024))
fi

if [ $TOTAL_RAM_MB -eq 0 ]; then
    echo "âš ï¸  Could not determine RAM size. Please ensure you have at least 16GB RAM."
    read -p "Continue anyway? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
else
    echo "ðŸ’¾ Total RAM: ${TOTAL_RAM_MB}MB"
    if [ $TOTAL_RAM_MB -lt 12000 ]; then
        echo "âŒ Insufficient RAM: ${TOTAL_RAM_MB}MB available, 12GB+ required for GPT-OSS-20B Q4"
        echo "ðŸ’¡ Consider using a smaller quantization (Q3) or ensure more RAM is available"
        exit 1
    elif [ $TOTAL_RAM_MB -lt 16000 ]; then
        echo "âš ï¸  Limited RAM: ${TOTAL_RAM_MB}MB available, 16GB+ recommended for optimal performance"
    else
        echo "âœ… RAM requirements met"
    fi
fi

# Check CPU cores
CPU_CORES=$(nproc 2>/dev/null || sysctl -n hw.ncpu 2>/dev/null || echo "1")
echo "ðŸ–¥ï¸  CPU cores: $CPU_CORES"
if [ $CPU_CORES -lt 4 ]; then
    echo "âš ï¸  Limited CPU cores. Performance may be slower."
fi

# Check available disk space
AVAILABLE_SPACE_KB=$(df . | tail -1 | awk '{print $4}')
AVAILABLE_SPACE_GB=$((AVAILABLE_SPACE_KB / 1024 / 1024))
echo "ðŸ’½ Available disk space: ${AVAILABLE_SPACE_GB}GB"

if [ $AVAILABLE_SPACE_GB -lt 15 ]; then
    echo "âŒ Insufficient disk space: ${AVAILABLE_SPACE_GB}GB available, 15GB+ required"
    exit 1
else
    echo "âœ… Disk space requirements met"
fi

echo ""
echo "ðŸ“‹ System Requirements Summary:"
echo "   RAM: $TOTAL_RAM_MB MB (12GB+ required)"
echo "   CPU: $CPU_CORES cores (4+ recommended)" 
echo "   Disk: $AVAILABLE_SPACE_GB GB (15GB+ required)"
echo ""

# Create models directory
echo "ðŸ“ Creating models directory..."
mkdir -p "$MODELS_DIR"

# Check if model already exists
MODEL_PATH="$MODELS_DIR/$GPT_OSS_VERSION"
if [ -f "$MODEL_PATH" ]; then
    echo "âœ… GPT-OSS-20B model already exists: $MODEL_PATH"
    echo "ðŸ“ Model size: $(du -h "$MODEL_PATH" | cut -f1)"
    
    read -p "Re-download model? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "ðŸš€ Skipping download. Proceeding to setup..."
        SKIP_DOWNLOAD=true
    else
        echo "ðŸ—‘ï¸  Removing existing model..."
        rm -f "$MODEL_PATH"
    fi
fi

# Download model if needed
if [ "$SKIP_DOWNLOAD" != "true" ]; then
    echo "â¬‡ï¸  Downloading GPT-OSS-20B model..."
    echo "ðŸ“¦ Model: $GPT_OSS_VERSION"
    echo "ðŸ”— URL: $DOWNLOAD_URL"
    echo "ðŸ“ Destination: $MODEL_PATH"
    echo ""
    echo "â³ This may take 15-45 minutes depending on your connection..."
    echo "   Model size: ~12GB"
    echo ""

    # Download with progress
    if command -v wget >/dev/null 2>&1; then
        wget --progress=bar:force:noscroll -O "$MODEL_PATH" "$DOWNLOAD_URL"
    elif command -v curl >/dev/null 2>&1; then
        curl -L --progress-bar -o "$MODEL_PATH" "$DOWNLOAD_URL"
    else
        echo "âŒ Neither wget nor curl found. Please install one of them."
        exit 1
    fi

    if [ $? -eq 0 ]; then
        echo "âœ… Model downloaded successfully"
        echo "ðŸ“ Downloaded size: $(du -h "$MODEL_PATH" | cut -f1)"
    else
        echo "âŒ Download failed"
        exit 1
    fi
fi

# Install Node.js dependencies
echo ""
echo "ðŸ“¦ Installing Node.js dependencies..."
cd services/core

# Check if node-llama-cpp is available
if npm list node-llama-cpp >/dev/null 2>&1; then
    echo "âœ… node-llama-cpp already installed"
else
    echo "ðŸ“¥ Installing node-llama-cpp..."
    npm install node-llama-cpp@latest || {
        echo "âš ï¸  node-llama-cpp installation failed, trying alternative..."
        npm install @node-llama/node-llama-cpp@latest || {
            echo "âŒ Failed to install llama.cpp bindings"
            echo "ðŸ’¡ You may need to install build tools: npm install -g node-gyp"
            exit 1
        }
    }
fi

cd ../..

# Create environment configuration
echo ""
echo "âš™ï¸  Creating environment configuration..."

# Add GPT-OSS configuration to .env
ENV_FILE=".env"
if [ ! -f "$ENV_FILE" ]; then
    echo "ðŸ“„ Creating .env file..."
    cp .env.example "$ENV_FILE" || touch "$ENV_FILE"
fi

# Check if GPT-OSS config already exists
if grep -q "GPT_OSS_MODEL" "$ENV_FILE"; then
    echo "âœ… GPT-OSS configuration already exists in .env"
else
    echo "ðŸ“ Adding GPT-OSS configuration to .env..."
    cat >> "$ENV_FILE" << EOF

# GPT-OSS-20B Configuration
GPT_OSS_MODEL=gpt-oss-20b-q4
GPT_OSS_MODELS_PATH=./gpt-oss-models
GPT_OSS_THREADS=auto
GPT_OSS_GPU_LAYERS=20
# GPT_OSS_GPU_MEMORY=8192  # Uncomment and set GPU memory in MB if you have a GPU

EOF
    echo "âœ… GPT-OSS configuration added"
fi

# Test the installation
echo ""
echo "ðŸ§ª Testing GPT-OSS-20B installation..."

# Create test script
cat > test-gpt-oss.js << 'EOF'
const GPTOSSModelService = require('./services/core/llm/gpt-oss-service');

async function testGPTOSS() {
    console.log('ðŸ”§ Testing GPT-OSS-20B Model Service...');
    
    const service = new GPTOSSModelService();
    
    try {
        // Health check before initialization
        const preHealth = await service.healthCheck();
        console.log('ðŸ“Š Pre-initialization health:', preHealth);
        
        // Initialize
        console.log('ðŸš€ Initializing GPT-OSS-20B...');
        const initialized = await service.initialize();
        
        if (initialized) {
            console.log('âœ… GPT-OSS-20B initialized successfully!');
            
            // Health check after initialization
            const postHealth = await service.healthCheck();
            console.log('ðŸ“Š Post-initialization health:', postHealth);
            
            // Quick test generation
            console.log('ðŸ§ª Running quick test...');
            const testPrompt = 'Generate a brief medical report structure in German.';
            const result = await service.generateReport(testPrompt, 'de');
            
            console.log('âœ… Test generation successful!');
            console.log('ðŸ“ˆ Performance:', {
                model: result.modelUsed,
                inference_time: result.inferenceTime + 'ms',
                tokens_generated: result.tokensGenerated
            });
            
            // Cleanup
            await service.cleanup();
            console.log('ðŸŽ‰ GPT-OSS-20B test completed successfully!');
            
        } else {
            console.log('âŒ GPT-OSS-20B initialization failed');
            process.exit(1);
        }
        
    } catch (error) {
        console.error('âŒ Test failed:', error.message);
        process.exit(1);
    }
}

testGPTOSS();
EOF

echo "ðŸƒ Running integration test..."
node test-gpt-oss.js

# Clean up test file
rm test-gpt-oss.js

echo ""
echo "ðŸŽ‰ GPT-OSS-20B Setup Complete!"
echo "================================"
echo ""
echo "ðŸ“‹ Installation Summary:"
echo "   âœ… Model downloaded: $MODEL_PATH"
echo "   âœ… Dependencies installed: node-llama-cpp"
echo "   âœ… Environment configured: .env"
echo "   âœ… Integration test passed"
echo ""
echo "ðŸš€ GPT-OSS-20B is now ready for offline medical report processing!"
echo ""
echo "ðŸ”§ Configuration:"
echo "   Model: GPT-OSS-20B MXFP4 (Recommended)"
echo "   RAM Usage: ~12-16GB during inference"
echo "   Performance: Medium speed, excellent quality"
echo "   Location: $MODEL_PATH"
echo ""
echo "ðŸ’¡ Usage Tips:"
echo "   - GPT-OSS-20B has highest priority in local model fallback"
echo "   - Will be automatically used when available"
echo "   - Fallback: Ollama â†’ Claude â†’ Gemini â†’ OpenAI"
echo ""
echo "ðŸ–¥ï¸  To start the system:"
echo "   docker-compose up -d"
echo ""
echo "ðŸ“Š Monitor GPT-OSS-20B:"
echo "   docker logs radiology-ai-system-websocket-proxy-1 | grep GPT-OSS"